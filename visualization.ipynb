{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########new dataset\n",
    "#images\n",
    "import argparse\n",
    "import pickle\n",
    "from torchvision.models import detection\n",
    "import torch\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "from PIL import Image\n",
    "from stacked_hourglass.datasets import generic\n",
    "import argparse\n",
    "import glob\n",
    "from albumentations.core.composition import KeypointParams\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "import torch\n",
    "import numpy as np\n",
    "from stacked_hourglass.predictor import HumanPosePredictor, GenericPosePredictor\n",
    "from stacked_hourglass.model import hg2\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import csv\n",
    "import glob\n",
    "import random\n",
    "import copy\n",
    "from PIL import Image\n",
    "import albumentations as A\n",
    "from stacked_hourglass.utils import finetune\n",
    "from stacked_hourglass import train as t\n",
    "from stacked_hourglass.datasets.mpii import Mpii\n",
    "from torch.nn import DataParallel\n",
    "from stacked_hourglass.utils.logger import Logger\n",
    "import os\n",
    "from stacked_hourglass.utils.misc import save_checkpoint, adjust_learning_rate\n",
    "from stacked_hourglass.train import do_training_epoch, do_validation_epoch\n",
    "import tqdm\n",
    "import argparse\n",
    "from stacked_hourglass.datasets.mpii import MPII_JOINT_NAMES\n",
    "import cv2\n",
    "from torch.optim.rmsprop import RMSprop\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import random\n",
    "\n",
    "#####################################################################################################\n",
    "parser = argparse.ArgumentParser(description='Train a stacked hourglass model.')\n",
    "# Model structure\n",
    "parser.add_argument('--arch', '-a', metavar='ARCH', default='hg2',\n",
    "                    choices=['hg1', 'hg2', 'hg8'],\n",
    "                    help='model architecture')\n",
    "# Training strategy\n",
    "parser.add_argument('--input_shape', default=(256, 256), type=int, nargs='+',\n",
    "                    help='Input shape of the model. Given as: (H, W)')\n",
    "parser.add_argument('-j', '--workers', default=4, type=int, metavar='N',\n",
    "                    help='number of data loading workers (default: 4)')\n",
    "parser.add_argument('--epochs', default=20, type=int, metavar='N',\n",
    "                    help='number of total epochs to run')\n",
    "parser.add_argument('--start-epoch', default=0, type=int, metavar='N',\n",
    "                    help='manual epoch number (useful on restarts)')\n",
    "parser.add_argument('--train-batch', default=16, type=int, metavar='N',\n",
    "                    help='train batchsize')\n",
    "parser.add_argument('--test-batch', default=16, type=int, metavar='N',\n",
    "                    help='test batchsize')\n",
    "parser.add_argument('--lr', '--learning-rate', default=2.5e-4, type=float,\n",
    "                    metavar='LR', help='initial learning rate')\n",
    "parser.add_argument('--momentum', default=0.9, type=float, metavar='M',\n",
    "                    help='momentum')\n",
    "parser.add_argument('--weight-decay', '--wd', default=0, type=float,\n",
    "                    metavar='W', help='weight decay (default: 0)')\n",
    "parser.add_argument('--schedule', type=int, nargs='+', default=[200, 201],\n",
    "                    help='Decrease learning rate at these epochs.')\n",
    "parser.add_argument('--gamma', type=float, default=0.1,\n",
    "                    help='LR is multiplied by gamma on schedule.')\n",
    "# Miscs\n",
    "parser.add_argument('-c', '--checkpoint', default='checkpoint/', type=str, metavar='PATH',\n",
    "                    help='path to save checkpoint (default: checkpoint)')\n",
    "parser.add_argument('--snapshot', default=0, type=int,\n",
    "                    help='save models for every #snapshot epochs (default: 0)')\n",
    "parser.add_argument('--resume', default='', type=str, metavar='PATH',\n",
    "                    help='path to latest checkpoint (default: none)')\n",
    "\n",
    "\n",
    "#heatmap check\n",
    "# haetmap output of the pre-trained model\n",
    "#from stacked_hourglass.train import generate_gaussian\n",
    "from stacked_hourglass.predictor import HumanPosePredictor, GenericPosePredictor\n",
    "device='cuda'\n",
    "model1 = hg2(pretrained=True)\n",
    "model1 = DataParallel(model1).to(device)\n",
    "input = torch.empty((1,3,256,256), device=device, dtype=torch.float32)\n",
    "#target = torch.zeros(1,20, 64, 64)\n",
    "input[0],target,meta=next(iter(train_loader))[1]\n",
    "#plt.imshow(np.array(input[0].to('cpu').permute(1,2,0)))\n",
    "with torch.enable_grad():\n",
    "        # Forward pass and loss calculation.\n",
    "        output1 = model1(input)\n",
    "'''for i in range(20):\n",
    "    plt.subplot(4,5,i+1)\n",
    "    plt.imshow(output1[0][0,i,:,:].to('cpu').detach().numpy())\n",
    "plt.show()'''\n",
    "\n",
    "# haetmap output of the trained model\n",
    "#input = torch.empty((1,3,256,256), device=device, dtype=torch.float32)\n",
    "#input[0]=predictor.prepare_image(torch.as_tensor(frame1))\n",
    "\n",
    "#plt.imshow(np.array(input[0].to('cpu').permute(1,2,0)))\n",
    "\n",
    "with torch.enable_grad():\n",
    "        # Forward pass and loss calculation.\n",
    "        output = model(input)\n",
    "for i in range(20):\n",
    "    plt.subplot(4,5,i+1)\n",
    "    plt.imshow(output[0][0,i,:,:].to('cpu').detach().numpy())\n",
    "    #plt.imshow(target[i].to('cpu').detach().numpy())\n",
    "plt.show()\n",
    "\n",
    "#landmark check\n",
    "image=cv2.imread('C:/Users/mobinamb/Desktop/Mobina work/pytorch pose estimation/transferlearning/pytorch-stacked-hourglass -571t/src/dataset/images/RGB1/s04_e02/colorImg716.jpg')\n",
    "#image=cv2.resize(image,(256,256),interpolation = cv2.INTER_AREA)\n",
    "device='cuda'\n",
    "frame1 = np.moveaxis(image, -1, 0)\n",
    "frame2 = torch.as_tensor(np.array(frame1, copy=True))\n",
    "\n",
    "model = DataParallel(model).to(device)\n",
    "predictor = HumanPosePredictor(model, device=device)\n",
    "joints = predictor.estimate_joints(frame2, flip=False)\n",
    "#image=np.array(input[0].to('cpu').permute(1,2,0))\n",
    "for i in range(len(joints)):\n",
    "    #plt.plot(int(joints[i][0]),int(joints[i][1]), color=\"white\", linewidth=5)\n",
    "    #plt.imshow(image)\n",
    "    frame=cv2.circle(image,(int(joints[i][0]),int(joints[i][1])),radius=5,color=(255,0,255),thickness=-1) # predicted purple pretrained\n",
    "plt.imshow(frame)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
