{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########new dataset\n",
    "#images\n",
    "import argparse\n",
    "import pickle\n",
    "from torchvision.models import detection\n",
    "import torch\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "from PIL import Image\n",
    "from stacked_hourglass.datasets import generic\n",
    "import argparse\n",
    "import glob\n",
    "from albumentations.core.composition import KeypointParams\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "import torch\n",
    "import numpy as np\n",
    "from stacked_hourglass.predictor import HumanPosePredictor, GenericPosePredictor\n",
    "from stacked_hourglass.model import hg2\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import csv\n",
    "import glob\n",
    "import random\n",
    "import copy\n",
    "from PIL import Image\n",
    "import albumentations as A\n",
    "from stacked_hourglass.utils import finetune\n",
    "from stacked_hourglass import train as t\n",
    "from stacked_hourglass.datasets.mpii import Mpii\n",
    "from torch.nn import DataParallel\n",
    "from stacked_hourglass.utils.logger import Logger\n",
    "import os\n",
    "from stacked_hourglass.utils.misc import save_checkpoint, adjust_learning_rate\n",
    "from stacked_hourglass.train import do_training_epoch, do_validation_epoch\n",
    "import tqdm\n",
    "import argparse\n",
    "from stacked_hourglass.datasets.mpii import MPII_JOINT_NAMES\n",
    "import cv2\n",
    "from torch.optim.rmsprop import RMSprop\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import random\n",
    "\n",
    "#####################################################################################################\n",
    "parser = argparse.ArgumentParser(description='Train a stacked hourglass model.')\n",
    "# Model structure\n",
    "parser.add_argument('--arch', '-a', metavar='ARCH', default='hg2',\n",
    "                    choices=['hg1', 'hg2', 'hg8'],\n",
    "                    help='model architecture')\n",
    "# Training strategy\n",
    "parser.add_argument('--input_shape', default=(256, 256), type=int, nargs='+',\n",
    "                    help='Input shape of the model. Given as: (H, W)')\n",
    "parser.add_argument('-j', '--workers', default=4, type=int, metavar='N',\n",
    "                    help='number of data loading workers (default: 4)')\n",
    "parser.add_argument('--epochs', default=20, type=int, metavar='N',\n",
    "                    help='number of total epochs to run')\n",
    "parser.add_argument('--start-epoch', default=0, type=int, metavar='N',\n",
    "                    help='manual epoch number (useful on restarts)')\n",
    "parser.add_argument('--train-batch', default=16, type=int, metavar='N',\n",
    "                    help='train batchsize')\n",
    "parser.add_argument('--test-batch', default=16, type=int, metavar='N',\n",
    "                    help='test batchsize')\n",
    "parser.add_argument('--lr', '--learning-rate', default=2.5e-4, type=float,\n",
    "                    metavar='LR', help='initial learning rate')\n",
    "parser.add_argument('--momentum', default=0.9, type=float, metavar='M',\n",
    "                    help='momentum')\n",
    "parser.add_argument('--weight-decay', '--wd', default=0, type=float,\n",
    "                    metavar='W', help='weight decay (default: 0)')\n",
    "parser.add_argument('--schedule', type=int, nargs='+', default=[200, 201],\n",
    "                    help='Decrease learning rate at these epochs.')\n",
    "parser.add_argument('--gamma', type=float, default=0.1,\n",
    "                    help='LR is multiplied by gamma on schedule.')\n",
    "# Miscs\n",
    "parser.add_argument('-c', '--checkpoint', default='checkpoint/', type=str, metavar='PATH',\n",
    "                    help='path to save checkpoint (default: checkpoint)')\n",
    "parser.add_argument('--snapshot', default=0, type=int,\n",
    "                    help='save models for every #snapshot epochs (default: 0)')\n",
    "parser.add_argument('--resume', default='', type=str, metavar='PATH',\n",
    "                    help='path to latest checkpoint (default: none)')\n",
    "\n",
    "\n",
    "#####################################################################################################\n",
    "args=parser.parse_args(args=[])\n",
    "final_train_val_data={}\n",
    "f = glob.glob(\"C:/Users/mobinamb/Desktop/Mobina work/pytorch pose estimation/transferlearning/pytorch-stacked-hourglass -571t/src/dataset/joints/*.txt\")[:-2]\n",
    "for name in f:\n",
    "    with open(name,'r') as ff:\n",
    "        data=ff.readlines()\n",
    "        for j in range(len(data)):\n",
    "            keyy=data[j].split()\n",
    "            valuee1=[]\n",
    "            for k in range(1,40,2):\n",
    "                valuee1.append((float(keyy[k]),float(keyy[k+1])))\n",
    "            name1=name.replace(name[-12:-11],\"/\")\n",
    "            b=name1.replace('joints','images/RGB1')\n",
    "            a='/colorImg'+str(keyy[0])+'.jpg'\n",
    "            name2=b.replace('.txt',a)\n",
    "            m1={name2:valuee1}\n",
    "            final_train_val_data.update(m1)\n",
    "\n",
    "\n",
    "# set the device we will be using to run the model\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# load the list of categories in the COCO dataset and then generate a\n",
    "# set of bounding box colors for each class\n",
    "#CLASSES = pickle.loads(open(args[\"labels\"], \"rb\").read())\n",
    "#COLORS = np.random.uniform(0, 255, size=(len(CLASSES), 3))\n",
    "\n",
    "# initialize a dictionary containing model name and its corresponding \n",
    "# torchvision function call\n",
    "MODELS = {\n",
    "    \"frcnn-resnet\": detection.fasterrcnn_resnet50_fpn,\n",
    "    \"frcnn-mobilenet\": detection.fasterrcnn_mobilenet_v3_large_320_fpn,\n",
    "    \"retinanet\": detection.retinanet_resnet50_fpn\n",
    "}\n",
    "# load the model and set it to evaluation mode\n",
    "model = MODELS[\"frcnn-resnet\"](pretrained=True, progress=True,\n",
    "    num_classes=91, pretrained_backbone=True).to(DEVICE)\n",
    "model.eval()\n",
    "\n",
    "\n",
    "# load the image from disk\n",
    "'''root='C:/Users/mobinamb/Desktop/Mobina work/pytorch pose estimation/transferlearning/pytorch-stacked-hourglass -571t/src/dataset/images/RGB'\n",
    "folders=os.listdir(root)\n",
    "for folder in folders:\n",
    "    images=os.listdir(root+'/'+folder)\n",
    "    for ii in range(len(images)):\n",
    "        image=cv2.imread(root+'/'+folder+'/'+images[ii])\n",
    "\n",
    "        orig = image.copy()\n",
    "        # convert the image from BGR to RGB channel ordering and change the\n",
    "        # image from channels last to channels first ordering\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        image = image.transpose((2, 0, 1))\n",
    "        # add the batch dimension, scale the raw pixel intensities to the\n",
    "        # range [0, 1], and convert the image to a floating point tensor\n",
    "        image = np.expand_dims(image, axis=0)\n",
    "        image = image / 255.0\n",
    "        image = torch.FloatTensor(image)\n",
    "        # send the input to the device and pass the it through the network to\n",
    "        # get the detections and predictions\n",
    "        image = image.to(DEVICE)\n",
    "        detections = model(image)[0]\n",
    "\n",
    "        idx = int(detections[\"labels\"][0])\n",
    "        boxx=list(detections.items())[0][1][0]\n",
    "        (startX, startY, endX, endY) = boxx.detach().cpu().numpy().astype(\"int\")\n",
    "        #cv2.rectangle(orig, (startX, startY), (endX, endY),\n",
    "        #    (2,0,0), 2)\n",
    "        w=endX-startX\n",
    "        h=endY-startY\n",
    "        \n",
    "        if 256-w>0:\n",
    "            startX=max(0,startX-(256-w)//2)\n",
    "            endX=min((256-w)//2+endX,orig.shape[1])\n",
    "        if 256-h>0:\n",
    "            startY=max(0,startY-(256-h)//2)\n",
    "            endY=min((256-h)//2+endY,orig.shape[1])\n",
    "        frame_new=orig[startY:endY,startX:endX]  \n",
    "        im_pil = Image.fromarray(frame_new) \n",
    "        #im_pil.save(root+'1/'+folder+'/'+images[ii])\n",
    "        if root+'1/'+folder+'/'+images[ii] in list(final_train_val_data.keys()):\n",
    "            final_train_val_data[root+'1/'+folder+'/'+images[ii]]=[(x-startX,y-startY) for (x,y) in final_train_val_data[root+'1/'+folder+'/'+images[ii]] ]\n",
    "        #else:\n",
    "            #os.remove(root+'1/'+folder+'/'+images[ii])\n",
    "    \n",
    "#prepare the correct dictionary format of the train-validation dataet {directory of the image:[(x,y) of the joints]}\n",
    "#create the dataset\n",
    "#1) save the whole images into a folder in src (dataset/images)\n",
    "#2) to create a data.npy file (a dictionary consisting of image number as key and its labels (x,y) as values)\n",
    "#3) create a list of unique random numbers (80%) from the number of image to build train data and (20%) to build validation data\n",
    "#you can remove train=np.load part of the code as you are spliting the train val data with code from one single dictionary\n",
    "\n",
    "train,val={},{}\n",
    "n_train=random.sample(range(1, len(final_train_val_data)), int(0.7*len(final_train_val_data)))\n",
    "s=list(final_train_val_data.items())\n",
    "for i in range(len(final_train_val_data)):\n",
    "    b={s[i][0]:s[i][1]}\n",
    "    if i in n_train and cv2.imread(s[i][0]) is not None:\n",
    "        train.update(b)\n",
    "    elif i not in n_train and cv2.imread(s[i][0]) is not None:\n",
    "        val.update(b)'''\n",
    "with open('saved_train.pkl', 'rb') as f:\n",
    "    train = pickle.load(f)\n",
    "with open('saved_val.pkl', 'rb') as f1:\n",
    "    val = pickle.load(f1)      \n",
    "#####################################################################################################\n",
    "train_dataset=generic.Generic(train,True)\n",
    "val_dataset=generic.Generic(val,False)\n",
    "train_loader= DataLoader(train_dataset,batch_size=args.train_batch, shuffle=True,num_workers=0, pin_memory=True,collate_fn=lambda x: x)\n",
    "val_loader= DataLoader(val_dataset, batch_size=args.train_batch,shuffle=False,num_workers=0, pin_memory=True,collate_fn=lambda x: x)\n",
    "#prepare the model\n",
    "model = hg2(pretrained=True) # first get the base model with 16 outputs\n",
    "#model=torch.load('model.pth')\n",
    "# set the pre-trained model's weight untrainable        \n",
    "for parameter in model.parameters():\n",
    "        parameter.requires_grad = False \n",
    "#change the number of outputs\n",
    "finetune.change_hg_outputs(model,[None,None,None,9,13,12,15,14,11,10,None,None,3,2,4,1,5,0,None,None])\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "            device = torch.device('cuda', torch.cuda.current_device())\n",
    "            torch.backends.cudnn.benchmark = True\n",
    "else:\n",
    "            device = torch.device('cpu')\n",
    "model = DataParallel(model).to(device)\n",
    "max_epoch=args.epochs\n",
    "batch_size=args.train_batch\n",
    "param_optimizer = list(model.parameters())\n",
    "from stacked_hourglass.utils import misc\n",
    "optimiser=torch.optim.Adam(param_optimizer, lr=args.lr,weight_decay=args.weight_decay)\n",
    "best_acc = 0\n",
    "\n",
    "#####################################################################################################\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
